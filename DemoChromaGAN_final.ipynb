{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DemoChromaGAN_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pvitoria/ChromaGAN/blob/master/DemoChromaGAN_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jaPdHaiS7-5",
        "colab_type": "text"
      },
      "source": [
        "# ChromaGAN Demo\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "This notebook allows you to colorize your images using ChromaGAN. \n",
        "\n",
        "Basic instructions:\n",
        "0.   Set GPU (Edit > Notebook settings or Runtime > Change runtime type and select GPU as Hardware accelerator.)\n",
        "1.   To execute a cell you have to select the corresponding cell by clicking on it and then click on the play icon that appears at the left top corner of the code.\n",
        "2.   To replicate the results obtained in the paper ChromaGAN execute cell number 1.\n",
        "3.   To colorize your own images execute cells number 2.1 and 2.2 in order. The execution of a cell has to end before starting the execution of the following one.\n",
        "\n",
        "If you use this demo for your research, please cite our paper [ChromaGAN: Adversarial Picture Colorization with Semantic Class Distribution](https://openaccess.thecvf.com/content_WACV_2020/papers/Vitoria_ChromaGAN_Adversarial_Picture_Colorization_with_Semantic_Class_Distribution_WACV_2020_paper.pdf):\n",
        "\n",
        "```\n",
        "\n",
        "@inproceedings{vitoria2020chromagan,\n",
        "  title={ChromaGAN: Adversarial Picture Colorization with Semantic Class Distribution},\n",
        "  author={Vitoria, Patricia and Raad, Lara and Ballester, Coloma},\n",
        "  booktitle={The IEEE Winter Conference on Applications of Computer Vision},\n",
        "  pages={2445--2454},\n",
        "  year={2020}\n",
        "}\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbVKhMf6DnGl",
        "colab_type": "text"
      },
      "source": [
        "# Nueva sección"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFJfjYH2c-Wa",
        "colab_type": "text"
      },
      "source": [
        "# 1. Run demo on ChromaGAN images\n",
        "\n",
        "This first part runs ChromaGAN on the images used in our paper. The results will be saved in the folder chromagan_results/ and are also displayed one by one (left: grayscale image, center: colorized image, right: ground truth image) followed by the corresponding PSNR value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn0KNolEdDf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download weights if not done already\n",
        "! if [ ! -d MODEL ] ; \\\n",
        "  then mkdir MODEL; \\\n",
        "    wget http://dev.ipol.im/~lraad/chromaGAN/model/my_model_colorization.h5; \\\n",
        "    mv my_model_colorization.h5 MODEL/; \\\n",
        "  elif [ ! -f MODEL/my_model_colorization.h5 ] ; \\\n",
        "    then wget http://dev.ipol.im/~lraad/chromaGAN/model/my_model_colorization.h5; \\\n",
        "      mv my_model_colorization.h5 MODEL/; \\\n",
        "fi\n",
        "\n",
        "# get ChromaGAN images\n",
        "! if [ ! -d chromagan_images ] ; \\\n",
        "  then wget http://dev.ipol.im/~lraad/chromaGAN/data/chromagan_images.zip; \\\n",
        "    unzip chromagan_images.zip; \\\n",
        "    rm chromagan_images.zip; \\\n",
        "fi\n",
        "\n",
        "# ChromaGAN\n",
        "%tensorflow_version 1.x\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import tensorflow as tf\n",
        "from keras import applications\n",
        "from keras.models import load_model\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# DIRECTORY INFORMATION\n",
        "DATA_DIR = os.path.join('chromagan_images/')\n",
        "OUT_DIR = os.path.join('chromagan_results/')\n",
        "MODEL_DIR = os.path.join('MODEL/')\n",
        "# DATA INFORMATION\n",
        "BATCH_SIZE = 1\n",
        "# TRAINING INFORMATION\n",
        "PRETRAINED = \"my_model_colorization.h5\" \n",
        "\n",
        "class DATA():\n",
        "\n",
        "    def __init__(self, dirname):\n",
        "        self.dir_path =dirname\n",
        "        self.filelist = os.listdir(self.dir_path )\n",
        "        self.batch_size = BATCH_SIZE\n",
        "        self.size = len(self.filelist)\n",
        "        self.data_index = 0\n",
        "\n",
        "    def read_img(self, filename):\n",
        "        IMAGE_SIZE = 224\n",
        "        img = cv2.imread(filename, 3)\n",
        "        height, width, channels = img.shape\n",
        "        labimg = cv2.cvtColor(cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE)), cv2.COLOR_BGR2Lab)\n",
        "        labimg_ori = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)\n",
        "        return np.reshape(labimg[:,:,0], (IMAGE_SIZE, IMAGE_SIZE, 1)), labimg[:, :, 1:], img, np.reshape(labimg_ori[:,:,0], (height, width, 1))\n",
        "\n",
        "    def generate_batch(self):\n",
        "        batch = []\n",
        "        labels = []\n",
        "        filelist = []\n",
        "        labimg_oritList= []\n",
        "        originalList = [] \n",
        "        for i in range(self.batch_size):\n",
        "            filename = os.path.join(self.dir_path, self.filelist[self.data_index])\n",
        "            filelist.append(self.filelist[self.data_index])\n",
        "            greyimg, colorimg, original, labimg_ori = self.read_img(filename)\n",
        "            batch.append(greyimg)\n",
        "            labels.append(colorimg)\n",
        "            originalList.append(original)\n",
        "            labimg_oritList.append(labimg_ori)\n",
        "            self.data_index = (self.data_index + 1) % self.size\n",
        "        batch = np.asarray(batch)/255 # values between 0 and 1\n",
        "        labels = np.asarray(labels)/255 # values between 0 and 1\n",
        "        originalList = np.asarray(originalList)\n",
        "        labimg_oritList = np.asarray(labimg_oritList)/255\n",
        "        return batch, labels, filelist, originalList, labimg_oritList\n",
        "\n",
        "def deprocess(imgs):\n",
        "    imgs = imgs * 255\n",
        "    imgs[imgs > 255] = 255\n",
        "    imgs[imgs < 0] = 0\n",
        "    return imgs.astype(np.uint8)\n",
        "\n",
        "def reconstruct(batchX, predictedY):\n",
        "    result = np.concatenate((batchX, predictedY), axis=2)\n",
        "    result = cv2.cvtColor(result, cv2.COLOR_Lab2BGR)\n",
        "         \n",
        "    return result\n",
        "\n",
        "def sample_images():\n",
        "    avg_ssim = 0\n",
        "    avg_psnr = 0\n",
        "    VGG_modelF = applications.vgg16.VGG16(weights='imagenet', include_top=True) \n",
        "    save_path = os.path.join(MODEL_DIR, PRETRAINED)\n",
        "    colorizationModel = load_model(save_path)\n",
        "    test_data = DATA(DATA_DIR)\n",
        "    assert test_data.size >= 0, \"Your list of images to colorize is empty. Please load images.\"\n",
        "    assert BATCH_SIZE<=test_data.size, \"The batch size (\" + str(BATCH_SIZE)+ \") should be smaller or equal to the number of testing images (\" + str(data_test.size)+ \") --> modify it\"\n",
        "    total_batch = int(test_data.size/BATCH_SIZE)\n",
        "    print(\"\")\n",
        "    print(\"number of images to colorize: \" + str(test_data.size))\n",
        "    print(\"total number of batches to colorize: \" + str(total_batch))\n",
        "    print(\"\")\n",
        "    if not os.path.exists(OUT_DIR):\n",
        "      print('created save result path')\n",
        "      os.makedirs(OUT_DIR)\n",
        "    for b in range(total_batch):\n",
        "            batchX, batchY, filelist, original, labimg_oritList = test_data.generate_batch()\n",
        "            predY, _ = colorizationModel.predict(np.tile(batchX,[1,1,1,3]))\n",
        "            predictVGG =VGG_modelF.predict(np.tile(batchX,[1,1,1,3]))\n",
        "            loss = colorizationModel.evaluate(np.tile(batchX,[1,1,1,3]), [batchY, predictVGG], verbose=0)\n",
        "            for i in range(BATCH_SIZE):\n",
        "                originalResult = original[i]\n",
        "                height, width, channels = originalResult.shape\n",
        "                predY_2 = deprocess(predY[i])\n",
        "                predY_2 = cv2.resize(predY_2, (width,height))\n",
        "                labimg_oritList_2 =labimg_oritList[i]\n",
        "                predResult_2= reconstruct(deprocess(labimg_oritList_2), predY_2)\n",
        "                ssim= tf.keras.backend.eval( tf.image.ssim(tf.convert_to_tensor(originalResult, dtype=tf.float32), tf.convert_to_tensor(predResult_2, dtype=tf.float32), max_val=255))\n",
        "                psnr= tf.keras.backend.eval( tf.image.psnr(tf.convert_to_tensor(originalResult, dtype=tf.float32), tf.convert_to_tensor(predResult_2, dtype=tf.float32), max_val=255))\n",
        "                avg_ssim += ssim\n",
        "                avg_psnr += psnr\n",
        "                save_path = os.path.join(OUT_DIR, \"{:.8f}_\".format(psnr)+filelist[i][:-4] +\"_reconstructed.jpg\" )\n",
        "                cv2_imshow(np.concatenate((np.tile(labimg_oritList[i]*255,[1,1,3]), predResult_2, originalResult),axis=1))\n",
        "                cv2.imwrite(save_path, predResult_2)\n",
        "                print(\"\")\n",
        "                print(\"Image \" + str(i+1) + \"/\" +str(BATCH_SIZE) + \" in batch \" + str(b+1) + \"/\" +str(total_batch) + \". From left to right: grayscale image to colorize, colorized image ( PSNR =\", \"{:.8f}\".format(psnr),\")\")\n",
        "                print(\"and ground truth image. Notice that PSNR has no sense in original black and white images.\")\n",
        "                print(\"\")\n",
        "                print(\"\")\n",
        "\n",
        "    print(\"average ssim loss =\", \"{:.8f}\".format(avg_ssim/(total_batch*BATCH_SIZE)))\n",
        "    print(\"average psnr loss =\", \"{:.8f}\".format(avg_psnr/(total_batch*BATCH_SIZE)))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    sample_images()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCIKt79VoYug",
        "colab_type": "text"
      },
      "source": [
        "# 2 Run demo on uploaded images\n",
        "\n",
        "This second part runs ChromaGAN on your selected images.\n",
        "\n",
        "## 2.1 Load images\n",
        "\n",
        "You can manually upload images from your computer. They can either be black and white images or color images. In the latter, the images are first transformed to their grayscale version and then colorized. \n",
        "\n",
        "Uploading images: first click on the folder icon located on the left. This will deploy the folders and files of the current directory. On top you'll find the upload icon that will allow you to upload all your images. These uploaded images will appear in your working directory and will later be automatically moved to the folder sample_images/.\n",
        "\n",
        "You can also directly download images from the web. For that, you have to add in the code cell below the following code line for each image to download:\n",
        "\n",
        "```\n",
        "!wget image_url\n",
        "```\n",
        "\n",
        "These images will also be saved in the current directory and will later be automatically moved to the folder sample_images/.\n",
        "\n",
        "An example for uploading one image from the web (replace this line by the lines corresponding to the images you want to download):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYolNxuUNMFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://upload.wikimedia.org/wikipedia/commons/thumb/0/00/Charlie_Chaplin.jpg/1024px-Charlie_Chaplin.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoatxJSRjYwB",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 Run demo\n",
        "\n",
        "The results will be saved in the folder sample_results/ and are displayed one by one (left: grayscale image, center: colorized image, right: ground truth image) followed by its PSNR value. In the case of a black and white images the PSNR value has no sense since we do not have the ground truth color version to compare with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PEKuaRQRjkE6",
        "colab": {}
      },
      "source": [
        "# download weights if not done already\n",
        "! if [ ! -d MODEL ] ; \\\n",
        "  then mkdir MODEL; \\\n",
        "    wget http://dev.ipol.im/~lraad/chromaGAN/model/my_model_colorization.h5; \\\n",
        "    mv my_model_colorization.h5 MODEL/; \\\n",
        "  elif [ ! -f MODEL/my_model_colorization.h5 ] ; \\\n",
        "    then wget http://dev.ipol.im/~lraad/chromaGAN/model/my_model_colorization.h5; \\\n",
        "      mv my_model_colorization.h5 MODEL/; \\\n",
        "fi\n",
        "\n",
        "# mv images to sample_images\n",
        "! if [ ! -d sample_images ] ; \\\n",
        "  then mkdir sample_images; \\\n",
        "fi\n",
        "!mv *.[pP][nN][gG] *.[jJ][pP][eE][gG] *.[jJ][pP][gG] *.[tT][iI][fF] *.[tT][iI][fF][fF] *.[pP][gG][mM] *.[bB][mM][pP] sample_images/ 2>/dev/null\n",
        "\n",
        "# ChromaGAN\n",
        "%tensorflow_version 1.x\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import tensorflow as tf\n",
        "from keras import applications\n",
        "from keras.models import load_model\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import math\n",
        "\n",
        "# DIRECTORY INFORMATION\n",
        "DATA_DIR = os.path.join('sample_images/')\n",
        "OUT_DIR = os.path.join('sample_results/')\n",
        "MODEL_DIR = os.path.join('MODEL/')\n",
        "# DATA INFORMATION\n",
        "BATCH_SIZE = 1\n",
        "# TRAINING INFORMATION\n",
        "PRETRAINED = \"my_model_colorization.h5\" \n",
        "\n",
        "class DATA():\n",
        "\n",
        "    def __init__(self, dirname):\n",
        "        self.dir_path =dirname\n",
        "        self.filelist = os.listdir(self.dir_path )\n",
        "        self.batch_size = BATCH_SIZE\n",
        "        self.size = len(self.filelist)\n",
        "        self.data_index = 0\n",
        "\n",
        "    def read_img(self, filename):\n",
        "        IMAGE_SIZE = 224\n",
        "        MAX_SIDE = 1500\n",
        "        img = cv2.imread(filename, 3)\n",
        "        if img is None:\n",
        "          print(\"Unable to read image: \" + filename)\n",
        "          return False, False, False, False, False\n",
        "        height, width, channels = img.shape\n",
        "        if height > MAX_SIDE or width > MAX_SIDE:\n",
        "          print(\"Image \" + filename + \" is of size (\" + str(height) + \",\" + str(width) +  \").\")\n",
        "          print(\"The maximum image size allowed is (\" + str(MAX_SIDE) + \",\" + str(MAX_SIDE) +  \").\")\n",
        "          r = min(MAX_SIDE/height,MAX_SIDE/width)\n",
        "          height = math.floor(r*height) \n",
        "          width = math.floor(r*width)\n",
        "          img = cv2.resize(img, (width,height))\n",
        "          print(\"It has been resized to (\" + str(height) + \",\" + str(width) + \")\")\n",
        "        labimg = cv2.cvtColor(cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE)), cv2.COLOR_BGR2Lab)\n",
        "        labimg_ori = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)\n",
        "        return True, np.reshape(labimg[:,:,0], (IMAGE_SIZE, IMAGE_SIZE, 1)), labimg[:, :, 1:], img, np.reshape(labimg_ori[:,:,0], (height, width, 1))\n",
        "\n",
        "    def generate_batch(self):\n",
        "        batch = []\n",
        "        labels = []\n",
        "        filelist = []\n",
        "        labimg_oritList= []\n",
        "        originalList = [] \n",
        "        for i in range(self.batch_size):\n",
        "            filename = os.path.join(self.dir_path, self.filelist[self.data_index])\n",
        "            ok, greyimg, colorimg, original, labimg_ori = self.read_img(filename)\n",
        "            if ok:\n",
        "              filelist.append(self.filelist[self.data_index])\n",
        "              batch.append(greyimg)\n",
        "              labels.append(colorimg)\n",
        "              originalList.append(original)\n",
        "              labimg_oritList.append(labimg_ori)\n",
        "              self.data_index = (self.data_index + 1) % self.size\n",
        "        batch = np.asarray(batch)/255 # values between 0 and 1\n",
        "        labels = np.asarray(labels)/255 # values between 0 and 1\n",
        "        originalList = np.asarray(originalList)\n",
        "        labimg_oritList = np.asarray(labimg_oritList)/255\n",
        "        return batch, labels, filelist, originalList, labimg_oritList\n",
        "\n",
        "def deprocess(imgs):\n",
        "    imgs = imgs * 255\n",
        "    imgs[imgs > 255] = 255\n",
        "    imgs[imgs < 0] = 0\n",
        "    return imgs.astype(np.uint8)\n",
        "\n",
        "deOr choose your filesYowza, that’s a big file. Try again with a file smaller than 25MB.f reconstruct(batchX, predictedY):\n",
        "    result = np.concatenate((batchX, predictedY), axis=2)\n",
        "    result = cv2.cvtColor(result, cv2.COLOR_Lab2BGR)\n",
        "         \n",
        "    return result\n",
        "\n",
        "def sample_images():\n",
        "    avg_ssim = 0\n",
        "    avg_psnr = 0\n",
        "    VGG_modelF = applications.vgg16.VGG16(weights='imagenet', include_top=True) \n",
        "    save_path = os.path.join(MODEL_DIR, PRETRAINED)\n",
        "    colorizationModel = load_model(save_path)\n",
        "    test_data = DATA(DATA_DIR)\n",
        "    assert test_data.size >= 0, \"Your list of images to colorize is empty. Please load images.\"\n",
        "    assert BATCH_SIZE<=test_data.size, \"The batch size (\" + str(BATCH_SIZE)+ \") should be smaller or equal to the number of testing images (\" + str(data_test.size)+ \") --> modify it\"\n",
        "    total_batch = int(test_data.size/BATCH_SIZE)\n",
        "    print(\"\")\n",
        "    print(\"number of images to colorize: \" + str(test_data.size))\n",
        "    print(\"total number of batches to colorize: \" + str(total_batch))\n",
        "    print(\"\")\n",
        "    if not os.path.exists(OUT_DIR):\n",
        "      print('created save result path')\n",
        "      os.makedirs(OUT_DIR)\n",
        "    for b in range(total_batch):\n",
        "            batchX, batchY, filelist, original, labimg_oritList = test_data.generate_batch()\n",
        "            if batchX.any():\n",
        "              predY, _ = colorizationModel.predict(np.tile(batchX,[1,1,1,3]))\n",
        "              predictVGG =VGG_modelF.predict(np.tile(batchX,[1,1,1,3]))\n",
        "              loss = colorizationModel.evaluate(np.tile(batchX,[1,1,1,3]), [batchY, predictVGG], verbose=0)\n",
        "              for i in range(BATCH_SIZE):\n",
        "                  originalResult = original[i]\n",
        "                  height, width, channels = originalResult.shape\n",
        "                  predY_2 = deprocess(predY[i])\n",
        "                  predY_2 = cv2.resize(predY_2, (width,height))\n",
        "                  labimg_oritList_2 =labimg_oritList[i]\n",
        "                  predResult_2= reconstruct(deprocess(labimg_oritList_2), predY_2)\n",
        "                  ssim= tf.keras.backend.eval( tf.image.ssim(tf.convert_to_tensor(originalResult, dtype=tf.float32), tf.convert_to_tensor(predResult_2, dtype=tf.float32), max_val=255))\n",
        "                  psnr= tf.keras.backend.eval( tf.image.psnr(tf.convert_to_tensor(originalResult, dtype=tf.float32), tf.convert_to_tensor(predResult_2, dtype=tf.float32), max_val=255))\n",
        "                  avg_ssim += ssim\n",
        "                  avg_psnr += psnr\n",
        "                  save_path = os.path.join(OUT_DIR, \"{:.8f}_\".format(psnr)+filelist[i][:-4] +\"_reconstructed.jpg\" )\n",
        "                  cv2_imshow(np.concatenate((np.tile(labimg_oritList[i]*255,[1,1,3]), predResult_2, originalResult),axis=1))\n",
        "                  cv2.imwrite(save_path, predResult_2)\n",
        "                  print(\"\")\n",
        "                  print(\"Image \" + str(i+1) + \"/\" +str(BATCH_SIZE) + \" in batch \" + str(b+1) + \"/\" +str(total_batch) + \". From left to right: grayscale image to colorize, colorized image ( PSNR =\", \"{:.8f}\".format(psnr),\")\")\n",
        "                  print(\"and ground truth image. Notice that PSNR has no sense in original black and white images.\")\n",
        "                  print(\"\")\n",
        "                  print(\"\")\n",
        "\n",
        "    print(\"average ssim loss =\", \"{:.8f}\".format(avg_ssim/(total_batch*BATCH_SIZE)))\n",
        "    print(\"average psnr loss =\", \"{:.8f}\".format(avg_psnr/(total_batch*BATCH_SIZE)))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    sample_images()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}